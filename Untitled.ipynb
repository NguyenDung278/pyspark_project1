{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68ce55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a new SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Get SparkContext\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f325fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['367855\\t172-in-addr\\tarpa\\t1',\n",
       " '367856\\taddr\\tarpa\\t1',\n",
       " '367857\\tamphic\\tarpa\\t1',\n",
       " '367858\\tbeta\\tarpa\\t1',\n",
       " '367859\\tcallic\\tarpa\\t1',\n",
       " '367860\\tch\\tarpa\\t1',\n",
       " '367861\\td\\tarpa\\t1',\n",
       " '367862\\thome\\tarpa\\t7',\n",
       " '367863\\tiana\\tarpa\\t1',\n",
       " '367907\\tlocal\\tarpa\\t1']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Domains CSV File into an RDD\n",
    "common_crawl_domain_counts = sc.textFile('cc-main-limited-domains.csv')\n",
    "\n",
    "# Display first few domains from the RDD\n",
    "common_crawl_domain_counts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00aab3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 2 \n",
    "def fmt_domian_graph_entry(entry):\n",
    "    site_id, domain,tld,num_subdomains = entry.split('\\t')\n",
    "    return int(site_id),domain,int(num_subdomains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "271c1ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(367855, '172-in-addr', 1),\n",
       " (367856, 'addr', 1),\n",
       " (367857, 'amphic', 1),\n",
       " (367858, 'beta', 1),\n",
       " (367859, 'callic', 1),\n",
       " (367860, 'ch', 1),\n",
       " (367861, 'd', 1),\n",
       " (367862, 'home', 7),\n",
       " (367863, 'iana', 1),\n",
       " (367907, 'local', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formmated_host_counts = common_crawl_domain_counts.map(lambda e: fmt_domian_graph_entry(e))\n",
    "\n",
    "formmated_host_counts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3f4989b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 7, 1, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_subdomian_counts(entry):\n",
    "    site_id,domain,tld,num_subdomains = entry.split(\"\\t\")\n",
    "    return int(num_subdomains)\n",
    "\n",
    "\n",
    "host_count = common_crawl_domain_counts.map(lambda e: extract_subdomian_counts(e))\n",
    "host_count.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02be8183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595466"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_host_count = host_count.reduce(lambda a,b : a+b)\n",
    "total_host_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2087cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d678917a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/29 15:33:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c535c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----+---+\n",
      "|_c0   |_c1        |_c2 |_c3|\n",
      "+------+-----------+----+---+\n",
      "|367855|172-in-addr|arpa|1  |\n",
      "|367856|addr       |arpa|1  |\n",
      "|367857|amphic     |arpa|1  |\n",
      "|367858|beta       |arpa|1  |\n",
      "|367859|callic     |arpa|1  |\n",
      "+------+-----------+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_crawl = spark.read \\\n",
    "    .option('delimiter', '\\t') \\\n",
    "    .option('inferSchema', True) \\\n",
    "    .csv('cc-main-limited-domains.csv')\n",
    "\n",
    "# Display the DataFrame to the notebook\n",
    "common_crawl.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d2b9598",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_crawl=common_crawl.withColumnRenamed(\"_c0\",\"site_id\")\\\n",
    "            .withColumnRenamed(\"_c1\",\"domain\")\\\n",
    "            .withColumnRenamed(\"_c2\",\"top_level_domain\")\\\n",
    "            .withColumnRenamed(\"_c3\",\"num_subdomains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0547d5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----------------+--------------+\n",
      "|site_id|domain     |top_level_domain|num_subdomains|\n",
      "+-------+-----------+----------------+--------------+\n",
      "|367855 |172-in-addr|arpa            |1             |\n",
      "|367856 |addr       |arpa            |1             |\n",
      "|367857 |amphic     |arpa            |1             |\n",
      "|367858 |beta       |arpa            |1             |\n",
      "|367859 |callic     |arpa            |1             |\n",
      "+-------+-----------+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_crawl.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d218447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- top_level_domain: string (nullable = true)\n",
      " |-- num_subdomains: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_crawl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5bd767fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----------------+--------------+\n",
      "|site_id|domain     |top_level_domain|num_subdomains|\n",
      "+-------+-----------+----------------+--------------+\n",
      "|367855 |172-in-addr|arpa            |1             |\n",
      "|367856 |addr       |arpa            |1             |\n",
      "|367857 |amphic     |arpa            |1             |\n",
      "|367858 |beta       |arpa            |1             |\n",
      "|367859 |callic     |arpa            |1             |\n",
      "+-------+-----------+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_crawl.toDF(\"site_id\",'domain','top_level_domain','num_subdomains').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8e2e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save common_craw1 use parquet\n",
    "common_crawl\\\n",
    "    .write\\\n",
    "    .parquet('./results/common_crawl/', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "474bfe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----------------+--------------+\n",
      "|site_id|domain     |top_level_domain|num_subdomains|\n",
      "+-------+-----------+----------------+--------------+\n",
      "|367855 |172-in-addr|arpa            |1             |\n",
      "|367856 |addr       |arpa            |1             |\n",
      "|367857 |amphic     |arpa            |1             |\n",
      "|367858 |beta       |arpa            |1             |\n",
      "|367859 |callic     |arpa            |1             |\n",
      "+-------+-----------+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- top_level_domain: string (nullable = true)\n",
      " |-- num_subdomains: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read from parquet directory\n",
    "common_crawl_domains = spark.read\\\n",
    "    .parquet('./results/common_crawl/')\n",
    "\n",
    "# Display the first few rows of the DataFrame and the schema in the notebook\n",
    "common_crawl_domains.show(5, truncate=False)\n",
    "common_crawl_domains.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f055eb",
   "metadata": {},
   "source": [
    "Querying Domain Counts with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed4e0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_crawl_domains.createOrReplaceTempView(\"crawl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c05b7e",
   "metadata": {},
   "source": [
    "## Calculate the total number of domains for each top-level domain in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8466c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|top_level_domain|count|\n",
      "+----------------+-----+\n",
      "|edu             |18547|\n",
      "|gov             |15007|\n",
      "|travel          |6313 |\n",
      "|coop            |5319 |\n",
      "|jobs            |3893 |\n",
      "|post            |117  |\n",
      "|map             |34   |\n",
      "|arpa            |11   |\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_crawl_domains\\\n",
    "    .groupby('top_level_domain')\\\n",
    "    .count()\\\n",
    "    .orderBy('count', ascending=False)\\\n",
    "    .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "189ab3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|top_level_domain|count|\n",
      "+----------------+-----+\n",
      "|edu             |18547|\n",
      "|gov             |15007|\n",
      "|travel          |6313 |\n",
      "|coop            |5319 |\n",
      "|jobs            |3893 |\n",
      "|post            |117  |\n",
      "|map             |34   |\n",
      "|arpa            |11   |\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate the DataFrame using SQL's `COUNT`, `GROUP BY`, and `ORDER BY`\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        top_level_domain, \n",
    "        COUNT(domain) AS count\n",
    "    FROM crawl\n",
    "    GROUP BY top_level_domain\n",
    "    ORDER BY COUNT(domain) DESC\n",
    "    \"\"\"\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d74a73a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+\n",
      "|top_level_domain|sum(num_subdomains)|\n",
      "+----------------+-------------------+\n",
      "|edu             |484438             |\n",
      "|gov             |85354              |\n",
      "|travel          |10768              |\n",
      "|coop            |8683               |\n",
      "|jobs            |6023               |\n",
      "|post            |143                |\n",
      "|map             |40                 |\n",
      "|arpa            |17                 |\n",
      "+----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_crawl_domains.groupBy('top_level_domain')\\\n",
    "                    .sum('num_subdomains')\\\n",
    "                    .orderBy('sum(num_subdomains)',ascending=False)\\\n",
    "                    .show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dae2e9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+\n",
      "|top_level_domain|total_count|\n",
      "+----------------+-----------+\n",
      "|edu             |484438     |\n",
      "|gov             |85354      |\n",
      "|travel          |10768      |\n",
      "|coop            |8683       |\n",
      "|jobs            |6023       |\n",
      "|post            |143        |\n",
      "|map             |40         |\n",
      "|arpa            |17         |\n",
      "+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select top_level_domain,\n",
    "    sum(num_subdomains) as total_count\n",
    "    from crawl\n",
    "    group by top_level_domain\n",
    "    order by sum(num_subdomains) desc\n",
    "    \"\"\"\n",
    ").show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282b22b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35ae67",
   "metadata": {},
   "source": [
    "How many sub-domains does nps.gov have? Filter the dataset to that website's entry, display the columns top_level_domain, domain, and num_subdomains in your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aafa08ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+--------------+\n",
      "|top_level_domain|domain|num_subdomains|\n",
      "+----------------+------+--------------+\n",
      "|gov             |nps   |178           |\n",
      "+----------------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_crawl_domains\\\n",
    "    .select(['top_level_domain', 'domain', 'num_subdomains'])\\\n",
    "    .filter(common_crawl_domains.domain == \"nps\")\\\n",
    "    .filter(common_crawl_domains.top_level_domain == \"gov\")\\\n",
    "    .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71ebc4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+--------------+\n",
      "|top_level_domain|domain|num_subdomains|\n",
      "+----------------+------+--------------+\n",
      "|gov             |nps   |178           |\n",
      "+----------------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using sql\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT top_level_domain, domain, num_subdomains\n",
    "    FROM crawl\n",
    "    WHERE domain = \"nps\" \n",
    "    AND top_level_domain = 'gov'\n",
    "    \"\"\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4513a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad29118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
